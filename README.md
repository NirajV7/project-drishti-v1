# Project Drishti V1

![Drishti Logo](/frontend/public/drishti-logo.png)

**Project Drishti is a next-generation command center for intelligent event management, transforming real-time security data into a proactive, responsive, and high-value business asset.**

This interactive dashboard is a demonstration of the core capabilities of the Drishti platform, showcasing how AI and multimodal data fusion can create safer, more efficient, and more memorable event experiences.

---

## Core Features

- **Real-time AI Monitoring:** Live CCTV feeds enhanced with AI-powered analysis for crowd density, atmospheric conditions (Est. Oxygen), and device density.
- **Advanced Simulation Engine:** A powerful interface for running multi-stage, narrative-driven demonstration scenarios that showcase the system's full capabilities.
- **AI-Powered Anomaly Detection:** Fuses data from multiple sources (visual, atmospheric) to autonomously detect, verify, and escalate threats.
- **Community-Powered Safety Network:** Engages attendees and staff through a simulated mobile app to resolve personal crises, such as a lost child, with precision and care.
- **AI-Assisted Lost & Found:** Utilizes anonymized movement data to conduct rapid, privacy-preserving searches for lost items, turning a major pain point into a seamless experience.
- **Post-Event Business Intelligence:** Transforms event data into the "Event Genome," a valuable asset for optimizing future events, and provides attendees with a personalized "Digital Rewind" of their journey.

---

## Getting Started

### Prerequisites

- [Node.js](https://nodejs.org/) (v16 or later)
- [npm](https://www.npmjs.com/)

### Installation & Setup

1.  **Navigate to the frontend directory:**
    ```bash
    cd frontend
    ```

2.  **Install dependencies:**
    ```bash
    npm install
    ```

3.  **Run the application:**
    ```bash
    npm start
    ```
    The professional dashboard will open in your browser at `http://localhost:3000`.

---

## Demonstration Scenarios Walkthrough

To run the demonstrations, navigate to the **Simulations** tab in the sidebar.

### Scenario 1: Multimodal Anomaly

This scenario demonstrates the system's ability to detect a potential threat, use multiple data sources to confirm it, and initiate an autonomous response.

1.  **Start Anomaly Simulation:** Click this button to begin. A camera feed in the **Dashboard** will show light smoke. A low-priority alert appears.
2.  **Multi-Modal Confirmation:** After a few seconds, the system confirms the threat using atmospheric sensors. The alert is upgraded to high-priority.
3.  **Autonomous Response:** The system automatically dispatches a security unit. The view switches to the **Map View** to show the dispatch route.
4.  **Surgical Intervention:** The presenter can then **Activate Project Echo** (to clear a path) and **Deploy Project Chimera** (a drone for visual confirmation).
5.  **End Simulation:** Click **End Simulation & Get Summary** to conclude the scenario. The AI Oracle will appear with a full summary of the event.

### Scenario 2: The Guardian Network

This scenario showcases how the system handles a personal crisis with care, precision, and community support.

1.  **Start Guardian Simulation:** A floating panel for "Priya's App View" appears, showing a lost child alert.
2.  **Task Sonic Shield:** In the Simulations tab, click **Listen (No Distress)** or **Listen (Distress Detected)**. A "Live Soundscape Analysis" panel appears. The "Distress" variation will show a more urgent alert.
3.  **Guide with Live View:** In Priya's app panel, click **Guide Me with Live View**. The panel will switch to a video showing AR navigation.
4.  **Simulate Hidden Threat:** In the Simulations tab, click **Simulate Distress & Follower**. A "Biometric Status" panel appears, showing Priya's elevated heart rate.
5.  **Activate Guardian Network:** Click this button to trigger the community response. A "Guardian's App View" panel appears.
6.  **Deploy Companion Drone:** Click this button. A drone animation plays, and then the CCTV view switches to the "KILI DRONE - LIVE" feed for final confirmation.

### Scenario 3: Project Kosh (AI Lost & Found)

This scenario demonstrates a fast, efficient, and privacy-preserving search for a lost item.

1.  **Start Lost Item Simulation:** A floating panel for "Arjun's App View" appears with a report form.
2.  **Submit Report:** Click the submit button in Arjun's app. The view will switch to the **Map View**.
3.  **Surgical Search & Discovery:** An alert appears, and an animated "vector path" is drawn on the map. After a few seconds, the animation stops, a star marks the location, and a video feed of the found item appears.
4.  **Secure Recovery:** The system automatically dispatches a staff member (visible on the map) and sends a "Good news!" notification to Arjun's app. A final "RECOVERY COMPLETE" alert is shown.

### Final Scenario: Project Akashic (The Living Memory)

This concludes the entire demonstration.

1.  **End Event & Activate Project Akashic:** Click this button in the Simulations panel.
2.  **Processing:** The screen will fade to a "Processing Event Data..." message.
3.  **The Event Genome:** After a few seconds, you will be taken to the **Akashic BI** dashboard, a mockup of the post-event analytics view.
4.  **The Digital Rewind:** If you re-open Arjun's app panel, it will now show a notification. Clicking it plays the final "Digital Rewind" video. 